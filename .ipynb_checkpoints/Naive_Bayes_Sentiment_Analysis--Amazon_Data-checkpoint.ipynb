{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import scipy.stats as stats\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Good case, Excellent value.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Great for the jawbone.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tied to charger for conversations lasting more...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The mic is great.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I have to jiggle the plug to get it to line up...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>If you have several dozen or several hundred c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>If you are Razr owner...you must have this!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Needless to say, I wasted my money.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>What a waste of money and time!.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>And the sound quality is great.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>He was very impressed when going from the orig...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>If the two were seperated by a mere 5+ ft I st...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Very good quality though</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>The design is very odd, as the ear \"clip\" is n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Highly recommend for any one who has a blue to...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               review  sentiment\n",
       "0                         Good case, Excellent value.          1\n",
       "1                              Great for the jawbone.          1\n",
       "2   Tied to charger for conversations lasting more...          0\n",
       "3                                   The mic is great.          1\n",
       "4   I have to jiggle the plug to get it to line up...          0\n",
       "5   If you have several dozen or several hundred c...          0\n",
       "6         If you are Razr owner...you must have this!          1\n",
       "7                 Needless to say, I wasted my money.          0\n",
       "8                    What a waste of money and time!.          0\n",
       "9                     And the sound quality is great.          1\n",
       "10  He was very impressed when going from the orig...          1\n",
       "11  If the two were seperated by a mere 5+ ft I st...          0\n",
       "12                           Very good quality though          1\n",
       "13  The design is very odd, as the ear \"clip\" is n...          0\n",
       "14  Highly recommend for any one who has a blue to...          1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews = pd.read_csv('https://raw.githubusercontent.com/medytative/data/master/amazon_cells_labelled.txt', delimiter='\\t')\n",
    "reviews.columns = ['review','sentiment']\n",
    "reviews.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "positive_keywords = ['good','great','excellent','love','best','nice','right','happy']\n",
    "\n",
    "negative_keywords = ['waste','bad','poor','hate','disappoint']\n",
    "\n",
    "negating_keywords = ['not','don\\'t', 'doesn\\'t','couldn\\'t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model1 = pd.DataFrame(reviews.review)\n",
    "model1['sentiment'] = reviews.sentiment\n",
    "\n",
    "for key in positive_keywords:\n",
    "        model1[key] = model1.review.str.contains(key, case=False)\n",
    "        \n",
    "for key in negative_keywords:\n",
    "        model1[key] = model1.review.str.contains(key, case=False)\n",
    "        \n",
    "for key in negating_keywords:\n",
    "        model1[key] = model1.review.str.contains(key, case=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for significant feature correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a11807898>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZYAAAEnCAYAAACKbmVGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJztnXm8HFW1tp83YQoyBBQVmYKIImOA\nBAQBEVBxYFIQERUQRVSchw+vCoiXi4iKVxwwejGACigORC6CiMwIJIEwqoCAgnAVhECYAsl5vz/2\nblLpdJ+uru5zuvtkPfnVr7t21aq9q0+nV+291n63bBMEQRAE3WJcrxsQBEEQjC3CsQRBEARdJRxL\nEARB0FXCsQRBEARdJRxLEARB0FXCsQRBEARdJRxLEATBgCPpVEn/knRLk+OS9C1Jd0q6SdJWhWMH\nSbojbwd1oz3hWIIgCAaf6cDuwxx/I7Bh3g4DvgcgaXXgaGBbYBvgaEmrddqYcCxBEAQDju3LgYeH\nOWUv4HQnrgEmSloTeANwke2HbT8CXMTwDqoU4ViCIAjGPmsB9xb278tlzco7YplOLzBWePahuypr\n23x3q6Mq1/uy+Qsr2960wvhKdqpcIzyuocq2y7t6zdf50cq264xbsbLtlU/f2/qkJqiDT3qhq3/O\nL15u1Up2980f7oF3eO6ce39l2y1fsEFl204+43WXrfY5AZzztxmd/DcC2vvNWW6NDT5AGsKqMc32\ntDaqa9ReD1PeEeFYgiAIesFQ+YfK7ETacST13AesU9hfG7g/l+9cV35pB/UAozwUJmmypDcV9veU\ndOQI17mzpO1Hso4gCIK28VD5rXNmAO/J2WGvAh61/QBwIfB6SavloP3rc1lHjHaPZTIwBTgfwPYM\n0g2PJDsDjwNXj3A9QRAE5RnqisMAQNKZpN+6F0i6j5TptSyA7VNIv7lvAu4EngQOyccelvRlYGa+\n1LG2q4+JZko7FknPA35G6iqNB76cG/kNYCXgIeBg2w9IuhS4FngtMBE4NO8fC0yQtANwPDABmGL7\nCEnTgaeAjYD1SDd+ELAdcK3tg3M7Xg98CVge+CtwiO3HJd0DnAbsQfpA9wOeBg4HFkp6F/AR21e0\n+yEFQRB0G3enJ5Kv5QNaHDfw4SbHTgVO7VpjaG8obHfgfttb2N4UuAA4GdjX9ta5YccVzl/G9jbA\nx4GjbT8DHAWcbXuy7bMb1LEasAvwCeA3wEnAJsBmeRjtBcAXgN1sbwXMAj5ZsH8ol38P+LTte4BT\ngJNyneFUgiDoD4aGym8DRjuO5WZgN0knSNqRFAjaFLhI0hzSD/7ahfN/mV9nA5NK1vGb7FlvBv5p\n+2Ynt35rvsargI2Bq3KdB5F6N5XqlHSYpFmSZv3w9DNLNjEIgqALjG6MZVQpPRRm+3ZJW5PG6Y4n\nTaS51fZ2TUzm59eFbdRTsxkqvK/tL5OvddEw3b626ixmWnSSbhwEQdA2C5/tdQtGjNI9FkkvAZ60\n/WPgayQJgDUkbZePLytpkxaXmQesXLWxwDXAqyW9LNe5oqSXj3CdQRAE3SeGwgDYDLguD0F9nhQv\n2Rc4QdKNwBygVVrvJcDGkuZI2r/dxtp+EDgYOFPSTSRHs1ELs98A++Q6d2y3ziAIgpHAHiq9DRrt\nDIVdSOP85p0anLtz4f1D5HhHTmObWnf69Hzs4ILNPaT4DQ2O/aHBNbA9qfB+FnnSj+3bgc0b3lQQ\nBEGvGMCeSFli5n0QBEEvGMCeSFnCsWQ60fv60PXHVrZ9y5YNU8tLsXKa/9Q2negrPdOGDEU96417\nXmXbFaimiwYw19WDpGstO7Gyba9YRtU+qy0mVNce3LID238PPV3ZdnwH3+WJWq6ybVcYw8H7cCxB\nEAS9YAwPhY152XxJk5qtqhYEQdAzYh5LEARB0FXGcI+l7xyLpC8CB5IWn3mINIv+9yRplhVJ+mDv\ntf2IpMlNymsSM08CV47+XQRBEAyPXT1e2e/01VCYpCnA24AtgbeSlJABTgf+n+3NSXIvR7co/xHw\n0WFUAYIgCHrLGB4K6yvHAuwAnGv7KdvzSJMbnwdMtH1ZPuc0YCdJq5YsP6NZZUWtsKsfv2NEbigI\ngqAhCxeU3waMfnMsHS/3ma9RSvfL9jTbU2xP2X6lDbtQdRAEQUmGFpbfBox+cyxXAntIWkHSSsCb\ngSeARwpyLO8GLrP9aJPyucCjec0XSPGaIAiC/mIMD4X1VfDe9kxJM4Abgb+R1lt5lCSPf4qkFYG7\nyKufDVN+CHCqpCfpwjKbQRAEXSeywkaVr9k+JjuLy4Gv255DWotlMYYpnw1sUSg6ZoTaGgRBUI0B\n7ImUpR8dyzRJGwMrAKfZvr7XDQqCIOg60WMZPWy/sxf1vmx+9QBZJ3pf593wncq2u08+vJLdquNX\nqFznwnJ5EQ2ZT/X/SI8PPVPZtpM2d6Kr1gnuoM3jK9o+0oFm17yh+a1PasKKqqZ5B6CKumgAc139\nO9UNHFphQRAEQVeJHstgkmfmv8T2+b1uSxAEwWKM4RhLv6UbN0VSFSc4GXhTt9sSBEHQMWN4aeK+\n6bE00Qh7C3A18GpghqTTSdpg62azj9u+StI2wDeBCcBTpHTju4FjgQl5Tsvxts8exVsKgiBozhju\nsfSFY6nTCFsGuJ7kWCDJs7wmn/dT4CTbV0palzRH5ZXAn4GdbC+QtBvwX7bfJukoYIrtI0b5loIg\nCIZnAKVaytIXjoWCRhiApN8UjhV7GbsBG0vPZeqsImllYFXgNEkbkuRcSqWZSDoMOAzgiJWnsPuE\nl3V0E0EQBKUZwCGusvSLYxkup/OJwvtxwHY1B/ScsXQycIntfSRNAi4tU6ntacA0gP990QHV8zuD\nIAjaZQw7ln4J3jfSCGvE74DnhrVy1hekHss/8vuDC+fPA1bublODIAi6wBjWCusLx2J7JlDTCPsl\nizTC6vkoMEXSTZJuA2ozBL8KHC/pKqA4Y+oS0tDZHEn7j9gNBEEQtEtkhY0KjTTCflA8wfZDwBIO\nwvYfgZcXir6Yyx8Gpo5ck4MgCCoygD2RsvSTYwmNsCAIlh4iK2zk6ZVGWI2bVqiuObRyuSS0hlTV\n+wK4YM4plez22eojlevshH8MPVnZdrkONKHG7nNhY5apqm/WgSza8h38fSaM60ArrINGP9vrHsMA\nDnGVpW8cSxAEwVLFGHYsfRG8r0fSwZK+nd8fI+nTFa8zSVJPe0JBEAQNsctvA0ZfOpYuMgkIxxIE\nQf/R5awwSbtL+oukOyUd2eD4STlDdo6k2yXNLRxbWDg2o9Nb68ixSHqXpOtyY74vaT1Jd0h6gaRx\nkq6Q9Pp87ntymvCNks7IZWtI+oWkmXl7dYv6NpB0gaTZ+dob5fLpkr4l6WpJd0naN5t8Bdgxt+8T\nndxrEARBV+miY1FamOY7wBuBjYEDcjLUc9j+hO3JticDJ5OmdtR4qnbM9p6d3lrlGIukV5JSf19t\n+1lJ3wVeA5xAEoq8FrjN9u8kbQJ8Pp/7kKTV82X+m8baX82YBhxu+w5J2wLfBXbJx9YkScNsRJoT\ncw5wJPBp22+pep9BEAQjQnezwrYB7rR9F4Cks4C9gNuanH8AcHQ3G1Ckk+D9rsDWwMys3TUB+Fee\ni7IfafJibWb8LsA5eR5KbX4JNNf+WoI8I3974OeF85cvnPJr20PAbZJeVOYGilphe6++DdustGEZ\nsyAIgs7pbuxkLZIyfI37gG0bnShpPWB94A+F4hUkzQIWAF+x/etOGtOJYxFpvsnnFitMExzXzrsr\nkWRVBA3XS22m/dWovnHA3NyNa0RxbdRSOYhFrbDj13vX4EXIgiAYXNrICis+BGem5d+v505pYNbs\nN+0dpAf94nrs69q+X9JLgT9Iutn2X0s3sI5OYiwXA/tKeiGApNWzJzwB+AlwFPCDwrlvl/T82rm5\nvJn21xLYfgy4O/eGUGKLFm0MrbAgCPqTNmIstqfZnlLYptVd7T5gncL+2sD9TWp+B3BmscD2/fn1\nLpKI75ad3Fplx2L7NuALwO8k3QRcRMrCmgqcYPsnwDOSDrF9K3AccJmkG4Fv5Ms00/5qxoHAofka\nt5LGEIfjJmBBThiI4H0QBP1Dd0UoZwIbSlpf0nIk57FEdpekVwCrAX8slK0mafn8/gWkhRWbxWZK\n0dEEybwiY/2qjK8qHH9r4f1pwGl19s20v6YD0/P7YwrldwO7Nzj/4Lr9lfLrs6RYUBAEQV/hBQtb\nn1T2WmmRwyNICVDjgVNt3yrpWGCW7ZqTOQA4y14swPNK4PuShkidja/kjkNlYuZ9EARBL+iypIzt\n84Hz68qOqts/poHd1cBm3WxLOJZMBzJJHekVrTp+hcq2VTW/fnX9yaNeZ9D/dPI97sR2qWVo7OYL\nhWMJgiDoBWNYKywcSxAEQS8Ix9I7JD1eC8YHQRCMGQZQXLIsfe9YgiAIxiRdzArrNwZG3ThPiDxR\n0i2Sbq6tYS/pbElvKpw3XdLbJI3P58/M82Q+0LvWB0EQ1NHdeSx9xcA4FuCtJO2xLUgaYydKWhM4\nizwXJk8M2pWUcnco8KjtqaRJm++XtH7xgpIOkzRL0qzrHr9j9O4kCIJgyOW3AWOQHMsOwJm2F9r+\nJ3AZyWH8Ftglzxx9I3B51h57PfAeSXNISsvPBxZTmSzKJIQAZRAEo4mHhkpvg8YgxVgaJsrbflrS\npcAbSD2XMwvnf8T2haPTvCAIgjYYwJ5IWQapx3I5sH+OnawB7ARcl4+dBRwC7EiSNCC/flDSsgCS\nXi7peaPc5iAIgsaM4RjLIPVYfgVsB9xIkoP+rO3/y8d+B5wOzLD9TC77IUkU83olHf4Hgb1HtcVB\nEATNGMNZYX3vWAqCkgY+k7f6c54lxVCKZUPAf+QtCIKgvxjDQ2F971hGi8dVvbv5zFD1J4+FTdfi\nGTk60fsKnbHydDLOPGiDH6uMW771SU3oxf+BvmAAh7jKEo4lCIKgF0SPJQiCIOgmg5hGXJa+zgqT\nNEnSLR1eY2dJ23erTUEQBF1hwVD5bcBYGnosOwOPA1f3uB1BEASLGMMxlr7usWSWkXRa1vs6R9KK\nkraWdJmk2ZIuzNIuSPqopNvyuWdJmgQcDnxC0hxJO/byRoIgCJ5jDEu6DEKP5RXAobavknQq8GFg\nH2Av2w9mMcrjgPcCRwLr254vaaLtuZJOAR63/bWe3UEQBEEdHkCHUZZB6LHca/uq/P7HJOmWTYGL\nsg7YF4C18/GbgJ9IehewoNWFiyKU18+7cwSaHgRB0IQx3GMZBMdS/6nOA261PTlvm9l+fT72ZuA7\nwNbAbEnD9siKIpRbrfyy7rc8CIKgGUND5bcBYxAcy7qStsvvDwCuAdaolUlaVtImksYB69i+BPgs\nMBFYieSIVu5Bu4MgCJozhrPCBsGx/Ak4SNJNwOrAycC+wAmSbgTmANsD44EfS7oZuAE4yfZc4DfA\nPhG8D4Kgn7Bdehs0+jp4b/seYOMGh+aQ1I3r2aHBNW4HNu9uy4IgCDpkAGMnZelrxzKaLO+Gy72U\nYr1x1dX453egCvWPoScr21alVzpjH5jy2cq2Dw49Xdm2E1bvQD/roaH5XWzJyPO0q+vlLatBGDgZ\nAcKxBEEQBN1kLKcbh2MJgiDoBWPYsQxkH1TSsZJ263U7giAIquIFLr0NGgPZY7F9VK/bEARB0BHR\nY+kNWd34T5J+IOlWSb+TNEHSdEn75nOmSrpa0o2SrpO0sqTxkk6UNDPrhn2g1/cSBEGwGENtbAPG\nIPRYNgQOsP1+ST8D3lY7IGk54Gxgf9szJa0CPAUcCjxqe6qk5YGrJP3O9t29uIEgCIJ6xnLwvq97\nLJm7bc/J72cDkwrHXgE8YHsmgO3HbC8AXg+8J2uJXQs8n+SgFqOoFTbr8dAKC4JgFIkeS08pJvQv\nBCYU9sWSWmK18o/YvnC4C9ueBkwD+PJ6B47dx4cgCPqOQQzKl2UQeizD8WfgJZKmAuT4yjLAhcAH\nJS2by18uqfosxiAIgi7jofJbGSTtLukvku6UdGSD4wdLejDLW82R9L7CsYMk3ZG3gzq9t0HosTTF\n9jN5PZaTJU0gxVd2A35IGjK7XpKAB4G9e9bQIAiCero4xCVpPEnZ/XXAfcBMSTNs31Z36tm2j6iz\nXR04GphCGgGanW0fqdqevnYsWSts08L+Eot15fjKqxqY/0fegiAI+o4ur0y8DXCn7bsAJJ0F7AXU\nO5ZGvAG4yPbD2fYiYHfgzKqN6WvHMppc50cr267A+Mq2jw89U9l2OVWvtxd0ovf1/VlfrWy771Yf\nrWzbCXM7+Nv2Yoy6kzo70UV70i3X5BsRxlFdH7ArdNexrAXcW9i/D9i2wXlvk7QTcDvwCdv3NrFd\nq5PGDHqMJQiCYCBpJ8ZSzGDN22F1l2vkJeuzA34DTLK9OfB74LQ2bNsieixBEAQ9YKiNjloxg7UJ\n9wHrFPbXBu6vu8a/C7s/AE4o2O5cZ3tp+dYtyUD0WCSdL2lii3MulTSlQflkSW8audYFQRBUwCq/\ntWYmsKGk9fPE8XcAM4onSFqzsLsnaRFFSFm0r5e0mqTVSPMAh52q0Yq+77HkrK632JVDXZNJ2Q7n\nd69VQRAEndHN4L3tBZKOIDmE8cCptm+VdCwwy/YM4KOS9gQWAA8DB2fbhyV9meScAI6tBfKr0peO\nRdIk4LfAJcB2wGRJa9h+SNIXgQNJwaaHgNmFbLH9JH2XtN79oaRZ98cCEyTtABxv++xRvZkgCIIG\neKi7yQO2z6fuAboo2Gv7c8DnmtieCpzarbb0pWPJvAI4xPaHJN0DkIe63gZsSWr79SSZlxrL2N4m\nD30dbXs3SUcBU+pzt4MgCHpJl9ON+4p+jrH8zfY1dWU7AOfafsr2PFKWQ5Ff5td6TbGGFDMt/vb4\n3ztucBAEQVmGFqr0Nmj0s2N5okFZq0+4piu2kBK9MdvTbE+xPWW9ldZtt31BEASV8ZBKb4NGPzuW\nRlwJ7CFpBUkrAW8uYTMPWHlkmxUEQdAedvlt0Bgox5LlW2YAN5KGvWYBrabMXwJsnEXX9h/hJgZB\nEJRiLPdY+jJ430AjbFLh8NdsHyNpReBy4Ov5nJ0L5z9EjrHktLmpI93mIAiCdhhEh1GWvnQsLZgm\naWNgBeA029d346LrjFuxsu1cP1vZdmEHygmDllTy4NDTlW070fs65/pv9aTeoc5UMUadTr5P8zuw\n7qTegRpyqWMQh7jKMnCOxfY7e92GIAiCThlaOMhucXgGzrEEQRCMBWIeS5eRNEnSLb2oOwiCoB8Y\nskpvg0b0WIIgCHqAB9BhlKWXg3zjJf1A0q2SfidpgqT3S5op6UZJv8iZX0iaLukUSVdIul3SW3L5\nwZLOlXRBXuv56Fz+ZUkfq1Uk6ThJvVntKQiCoAFjOd24l45lQ+A7tjcB5pI0wH5pe6rtLUiSzocW\nzp8EvIY0KfIUSSvk8m1IopSTSSKUU4D/AQ4CkDSOJCH9kxG/oyAIgpLEBMmR4W7bc/L7mrbXprlX\ncjPJWWxSOP9ntods3wHcBWyUyy+y/W/bT5EmTe6Q58H8W9KWpLUFbqhb5AZYXCvstnl3jcQ9BkEQ\nNGThwnGlt0Gjly2eX3hf0/aaDhxhezPgS6S5KjXq/bZblP+QtN7AITSRgy5qhW288kvbbX8QBEFl\nbJXeBo1+c4UrAw9IWpbUYymyn6RxkjYAXgr8JZe/TtLqkiYAewNX5fJfAbuTZt13tBpaEARBtxnL\nQ2H9lhX2RdLiXH8DbmZx8ci/AJcBLwIOt/10WlySK4EzgJcBP7U9C8D2M5IuAebaXjh6txAEQdCa\nQUwjLktPHEsDLbCvFQ5/r4nZVbY/0aD8X40W8cpB+1cB+3XQ1CAIghFhEIe4ytJvPZaukLXEzgN+\nlYP9Lbny6Xsr17fWshMr26rlEjNBpwyiztig8djQ/NYnNeHNWqOy7aXMrWzbaxYOYBpxWQbCsdg+\nuEn5dFLAv778NlIcJgiCoC+JHksQBEHQVcZyjKXfssIqIWnvPPwVBEEwELiNbdAYE46FlGYcjiUI\ngoFhLItQ9syxSPpsTb9L0kmS/pDf7yrpx5K+l2fF3yrpSwW7r0i6TdJNkr4maXtgT+DEvPzwBnm7\nQNLsPJN/o8atCIIg6A1jeYJkL2MslwOfAr4FTAGWzxMjdwCuAH5u+2FJ44GLJW0O3AfsA2xk25Im\n2p4raQZwnu1zACRdTJrrcoekbYHvAruM+h0GQRA0YeEYzgjtpWOZDWwtaWWSvMv1JAezI/BR4O2S\nDiO1cU3SUNdtwNPADyX9LymleDEkrQRsD/w8T6AEWL5RA/L1DwNYa+X1WX3FF3Xt5oIgCIZjaBCD\nJyXpmWOx/ayke0haXlcDNwGvBTYAngI+DUy1/Yik6cAKthdI2gbYlaRYfARL9kTGkWbbTy7RhmnA\nNIDNX7zdGP4zB0HQbwyN4R5Lr4P3l5McyOWk4a/DgTnAKsATwKOSXgS8EZ7rjaxq+3zg4ySpfIB5\nZPkX248Bd0vaL9tI0hajdkdBEAQlMCq9DRq9dixXkIa5/mj7n6Rhrits3wjcANxKUiauCUuuDJwn\n6SaSblhN4uUs4DOSbsgilQcCh0q6MV9jr9G6oSAIgjIMtbENGj2dIGn7YmDZwv7LC+8PbmK2TYPr\nXMWS6ca7d6GJQRAEI8Ig9kTKEjPvM6HZVY5Ourirj2uYQ1GKuUPPVLYd6mCK2dKkM9bJ33bNcc+r\nbDtHT1WveBAf5zMLet2AESQcSxAEQQ+IHksQBEHQVcawuHHPg/elkTRJ0i2jbRsEQTASDKHS26Ax\nMI4lCIJgLNFtEUpJu0v6i6Q7JR3Z4PgnC3JYF0tar3BsYZbEmpOVTDpi0IbClpF0GrAlcDvwHtI8\nmD2ACaSJlh/Ici9bk1KVnyQtXxwEQdA3LFD3eiJZ+uo7wOtI0lczJc3Ia1PVuAGYYvtJSR8Evgrs\nn489VWZSeVkGrcfyCmCa7c2Bx4APAd+2PdX2piTn8pZ87o+Aj9rerjdNDYIgaE6XeyzbAHfavsv2\nM6S5fYvN37N9ie0n8+41wNod30QTBs2x3JvnrAD8mCRY+VpJ10q6mSTvsomkVYGJti/L557R6GKS\nDssKyrP+/eQ/R7zxQRAENbo8QXItoLi++n25rBmHAr8t7K+QfwuvkbR3uSqbM2hDYfXO2yTl4im2\n75V0DLACoAbnLnmxglbYFi/ePrTCgiAYNdrJCisK5mam5d+v505pYNbwN03Su0iCv68pFK9r+35J\nLwX+IOlm238t38LFGbQey7qSakNbB7AodvJQ1hHbF8D2XJLO2A75+IGj28wgCILhaScrzPY021MK\n27S6y90HrFPYXxu4v75OSbsBnwf2tD2/Vm77/vx6F3ApKY5dmUFzLH8CDspaYasD3wN+ANwM/BqY\nWTj3EOA7kv5IUksOgiDoG7ocY5kJbChpfUnLkdTfF8vukrQl8H2SU/lXoXw1Scvn9y8AXk1aoqQy\nAzMUZvseGi8//IW81Z8/GyiqGh8zIg0LgiCowIIuTk/JS4ocAVwIjAdOtX2rpGOBWbZnACcCK7Fo\nraq/294TeCXwfUlDpM7GV+qyydpmYBzLSLPQvREdcgc6Vr2gk0/poaH5rU9qwqB1raF3OmNv3+pj\nlezGIRZU/D7O9TM85Wcr2U7Qsq1PasIgfi9qdPt/fl5O5Py6sqMK73drYnc1sFk32xKOJQgCgMpO\nBajsVJZmxrKkSziWIAiCHjDAwswtCccSBEHQA8KxjBEkjbe9sNftCIIg8BgeCuvb2FdWJP6zpNOy\naNo5klaUtGtegvhmSacW0uSald8j6ShJVwL79fSmgiAIMgva2AaNvnUsmXptsE8C04H9bW9G6nF9\nUNIKjcoL13na9g62zxrNxgdBEDSj2+rG/US/O5Z6bbBdgbtt357LTgN2IjmgRuU1zm508aJW2MNP\n/avRKUEQBCPCkMpvg0a/O5bSSxG0OP5Ew4sXZBJWn/DC9loWBEHQAV0Woewr+t2x1GuD/R6YJOll\nuezdwGXAn5uUB0EQ9CXhWHpHvTbYSSQNsJ9nmfwh4BTbTzcq71GbgyAIWrJQ5bdBo9/TjYdsH15X\ndjENlDdtNyufNDJNC4IgqM4g9kTK0u+OJQiCYEwyiNleZelbx5LVjDcdrfpevNyqlW2X0fjKtuM7\n+Hot0zJnIRhUqgpJAvzs+v+uZPepKZ+rXOedQ/Mq2/bqe6wurjlfhaEx7Fr61rEEQRCMZcbyUFjf\nBu/zzPtb2jh/b0mN1msJgiDoO2KC5GCwN40XAguCIOg7Fqj8Nmj0u2MZL+kHkm6V9DtJEyS9X9JM\nSTdK+kXWD9se2BM4UdIcSRvk7QJJsyVdIWmjXt9MEARBjSFcehs0+t2xbAh8x/YmwFzgbcAvbU+1\nvQVpnsuheQW0GcBnbE+2/VdgGvAR21sDnwa+25tbCIIgWJKxPBTW78H7u23Pye9nA5OATSX9JzCR\ntH7zhfVGklYCtmfR2s4Ayzc47zDgMICNJm7MWiut3e32B0EQNGQsB+/73bEUF0lfCEwgqRjvbftG\nSQcDOzewGwfMtT15uIvbnkbq2bDbOm8YxAeDIAgGlEEc4ipLvw+FNWJl4AFJywIHFsrn5WPYfgy4\nW9J+AEpsMeotDYIgaMLCNrZBYxAdyxeBa4GLSOKTNc4CPpMX+9qA5HQOlXQjcCuw16i3NAiCoAlj\nOXjft0Nh9TPvbX+tcPh7Dc6/iiXTjXcfkcYFQRB0yOC5i/L0rWMJgiAYy0TwfingvvkPV7bdYsJa\nlW0fGXq6sm1ViSUNoMZYJ2O2vfoP3Ks2V9X8+vqs4yvXufvkehHy8owbV/37uMa4FSrbPjw0v/VJ\nI4jHcJ8lHEsQBEEPiB5LAUnHAI8DqwCX2/59txvVRlvOB95pe+4w5xwM/M72/aPWsCAIghYsjB7L\nktg+qpsNqdiGN5U47WDgFiAcSxAEfcMgZnuVpdQwsKTPS/qLpN8Dr8hl0yXtm99/RdJtkm6S9LVc\ntoeka3P67+8lvSiXHyPpDEl/kHSHpPfn8p0lXS7pV/lap0gal48dIOlmSbdIOqHQrnskvSArIf+p\nga7YvsAU4CdZQ2xCFz+7IAgpGkTIAAAgAElEQVSCyizVa95L2hp4B2nZ37cCU+uOrw7sA2xie3Pg\nP/OhK4FX2d6SNMfkswWzzYE3A9sBR0l6SS7fBvgUsBmwAfDWfOwEYBdgMjBV0t4NmrqErpjtc4BZ\nwIFZQ+ypVvcbBEEwGriNf4NGmaGwHYFf2X4SQNKMuuOPAU8DP5T0v8B5uXxt4GxJawLLAXcXbM7N\nP/JPSbqE5FDmAtfZvivXcyawA/AscKntB3P5T4CdgF/XtaORrtiwFLXCXrTSekycsEYrkyAIgq4w\niD2RspTNiGzqMm0vIDmGX5DWRLkgHzoZ+LbtzYAPAMW8wPrreZjysrmI9bpiLZ2m7Wm2p9ieEk4l\nCILRZCz3WMo4lsuBfXLMYmVgj+LBrCS8qu3zgY+ThqsAVgX+kd8fVHfNvSStIOn5JBHJmbl8G0nr\n59jK/qThtGuB1+RYynjgAOCyNu7xOQ2xIAiCfmGBXXobNFo6FtvXA2cDc0i9kivqTlkZOE/STaQf\n/E/k8mNIsvVXAA/V2VwH/C9wDfDlQirwH4GvkLK47iYNwT0AfA64BLgRuN72uW3c43TglAjeB0HQ\nT3R7PRZJu+ckqzslHdng+PKSzs7Hr5U0qXDsc7n8L5Le0NGNUTLd2PZxwHHDnLJNA5tzgWYO4Hbb\nhzUof9L2/g2u9VPgpw3KJ+W3D9FEV8z2L0gOMQiCoG/oZrpxHs35DvA64D5gpqQZtm8rnHYo8Ijt\nl0l6Bykpan9JG5MStDYBXgL8XtLLbVcWVh5EdeMgCIKBp8sxlm2AO23fZfsZUiZuvaL7XsBp+f05\nwK5KKyHuBZxle77tu4E7adBZaIdRl3SxfUyT8kuBS0ezLUXunFt9/uSWHWiFzetAr2h5ja9k14lW\n2CrjlliIszRPV38AYvUO6p3fQf7NYx38fdYc97zKtg8MPVHZ9s6heZXsOtH7umDOKZVt99/645Vt\n5/nZyrad6Ix1gy5nha0F3FvYvw/Yttk5thdIehR4fi6/ps62+o8aoRUWBEHQExa24VqKUyMy0/IK\nuM+d0sCsvqvT7Jwytm0x5h1LaIUFQdCPtNNjKS6j3oT7gHUK+2uzpIxV7Zz7JC1Dytx9uKRtWywN\nMZaDSQGpIAiCvsF26a0EM4EN83SN5UjB+PrJ7DNYNPVjX+APThefAbwjZ42tT1Ixua6Texu4HktO\nkfstaY7L9qS5MnuRNMxOAVYE/gq8F9iVRVphTwHbhaxLEAT9QDezwnLM5AjgQmA8cKrtWyUdC8yy\nPQP4H+AMSXeSeirvyLa3SvoZcBuwAPhwJxlhMICOJbMhcIDt9+cP5G0kLbKP2L4sf5hH2/54/rA/\nbXtWLxscBEFQpNuSLnmS+vl1ZUcV3j8N7NfEttWUkrYY1KGwel2wDYCJtmsz8k8j6YkNi6TDJM2S\nNGuogyycIAiCdhnLki6D2mOp1wWbWOUixYDYMsutNXh/vSAIBpaFHrsylIPaY6nnUeARSTvm/Xez\nSE8stMKCIOg7xvJ6LIPaY2nEQSRNsBWBu4BDcvn0XB7B+yAI+oZBHOIqy8A5Ftv30EQXDHhVg/ND\nKywIgr5jLC9NPHCOJQiCYCxQcn7KQBKOJbPlCzaobPvvoacr266oZSvbThhX3bYqCzt4ylpW1UN6\nT3pBZdtOxqjfrOoLwM1R9VHXCR18L5apqAU3blx1DblO9L7Onv3Nyrbv3frTlW0f7OD/bTeIHksQ\nBEHQVSIrrAdIOkZS248jknaWNL3wfvuuNy4IgqBDur3QVz8x1nssOwOPA1f3uB1BEASLMZaHwvqq\nxyLp83lpzN+TtL+QNFnSNZJukvQrSavl8kslnSDpOkm3F+awPAM8mjXFDgc+kZcl3rFBlUEQBD1h\nCJfeBo2+6bFI2pokirYlqV3Xk+RaTqdOAwyoRQqXsb2NpDfl8t1sX03uoUg6BXi8LiU5CIKg54zl\nrLB+6rHsCPzK9pO2HyNJOT+P4TXAfplfZwOT2q2wqBX24JMPVG95EARBmyxkqPQ2aPSTY4H241Q1\nzbCFVOh92Z5me4rtKWusuGa75kEQBJXp8nosfUU/OZbLgX0kTZC0MrAH8ATNNcDKEDphQRD0JRFj\nGQVsXy/pbGAO8DfginyomQZYGX4DnCNpL1Kc5opWBkEQBKPBIPZEytI3jgWGXWymkQbYzoX3D9Eg\nxmL7dmDz7rUwCIKgOwxiT6QsfeVYgiAIlhZC3XgpQBX1lQDGd2Arja9u20G9SxOdBBIvZW514w6S\neXoR/Fxj3AqVbef52cq2neh9nTq7+kyCt2/1scq23WAsS7qEYwmCIOgBQxFjCYIgCLrJWB4KG9Ue\nd1VhyQr13JNfJ0r60EjXFwRB0C5Ddult0OineSwjwUQgHEsQBH2H2/g3aIy4Y2lTWHIDSRdImi3p\nCkkb5fL9JN0i6UZJl+eygyX9Mp9/h6SvFqp9ML9+Bdggi1CeONL3GgRBUJax3GMZ0RhLBWHJacDh\ntu+QtC3wXWAX4CjgDbb/IWlioYrJ+drzgb9IOtn2vban5uNHApvantykfYcBhwGst+qGvDBkXYIg\nGCWGvLDXTRgxRjp4/5ywJICkZsKSP5e0ErB9fl+zXz6/XgVMl/QzFglPAlxs+9F87duA9YB7yzbO\n9jSSM2Obl7xm8B4LgiAYWGKCZGeU/fTGAXMb9S5sH557MG8G5kiqnTO/cFolIcogCIJeMJYlXUY6\nxlJaWDJL5d8taT8AJbbI7zewfa3to4CHgHVK1h8ilEEQ9CVjWYRyRB2L7euBmrDkL1hcWPJESTeR\n4iTH5vIDgUMl3QjcCuyVy0+UdLOkW0jO6saS9f8buCoH/iN4HwRB3zCWZfNHfOioTWHJu4HdG5S/\ntYH99LzVznlLk/rfWbKpQRAEo0ZIuiwFrLvsqpVtJ2q5yrZz/Uxl22fH8BeznnGhi1aaQvJLWzw8\nNL/1SU3oRGfswaGnK9t2ovf1s+v/u7JtNxjEnkhZwrEEQRD0gEGMnZQlHEsQBEEPGMs9lr6UdJE0\nKQfqGx27VNKUFvbHSDo4vz9Y0ktGoJlBEASVGcsz7/vSsXSZg4FwLEEQ9BWjlRUmaXVJF2Xpq4tq\nElp150yW9EdJt2aprf0Lx6ZLujtLYxXnETZlRByLpPfkxt0o6QxJ60m6OJddLGndQoP3Ldg93uBa\nEySdlW3PBiYUz5d0XK7nGkkvyoceB57K154C/CR/IBPqrx8EQdALFnqo9NYhR5JUSjYELs779TwJ\nvMf2JqTM3G/WyWd9xvbkvM1pVWHXHYukTYDPA7vY3gL4GPBt4HTbmwM/Ab7VxiU/CDyZbY8Dti4c\nex5wTa7ncuD9ALa/Zvts2+cAs4AD8wfyVIe3FwRB0BVGcShsL5J0Fvl17/oTbN9u+478/n7gX8Aa\nVSsciR7LLsA5th8CsP0wsB3w03z8DGCHNq63E/DjfK2bgJsKx54BzsvvZwOT2mmopMMkzZI0667H\n/9aOaRAEQUeMomz+i2w/AJBfXzjcyZK2AZYD/looPi6PGp0kafkmps8xEo5FtNYHqx1fUGuDUvJ9\nswkhza73rBcNQLatFWZ7mu0ptqe8dKX12jENgiDoiHZ6LMWH4LwdVryWpN9nhZH6ba9m9TdC0pqk\nh/9D7OfG4D4HbARMBVYH/l+r64xEuvHFwK8knWT735JWB64myeefQZJtuTKfew9paOtnpO7asg2u\nd3m2uUTSpsDmbbYn9MKCIOg72gnKF5XYmxzfrdkxSf+UtKbtB7Lj+FeT81YB/hf4gu1rCtd+IL+d\nL+lHQMtVgLveY7F9KykWclnW/PoG8FHgkKwN9m5S3AXgB8BrJF0HbEsSqKzne8BK2fazwHVtNmk6\ncEoE74Mg6CeGPFR665AZJH1G8uu59SdIWg74FSkW/vO6Y2vmV5HiMw2ngixmM5Yn6bTDvuvtWfmD\nCEmXkSckXcpTVdKlk+yjXkm6dPK96ETSZdkXvLTjL+Syy61V+jfn2Wf+Ubk+Sc8njQqtC/wd2M/2\nw3k+4OG23yfpXcCPSOK/NQ62PUfSH0iBfJEEhQ+3vUQGb5GYeR8EQdADRuuRPqu879qgfBbwvvz+\nx+QkqQbn7VKl0tjKTVA6bGmxHbT2hm1/17k02i7t29Iw875bHNb6lDFjO2jtDdv+rnNptF2qCccS\nBEEQdJVwLEEQBEFXCcdSnqY55GPQdtDaG7b9XefSaLtUE+nGQRAEQVeJHksQBEHQVcKxBEEQBF0l\nHEsTJL26TNkI1LtfmbImth8rU9ZtBvGzGiQkjZP09h7VvYSSbRl12y7Yjvp3qpP2BosTjqU5J5cs\new5JN2dp6YZbyXo/V7KsEQc1KDu4pC15Qbbd8vsJksqKd7b9WXWp3sqflaQjGq2kV8Lu5Xmxulvy\n/uaSvlDCrvJ3w0ll9oh229ppmzN/LFnWbdtK3ylJJ5Qpa0In7Q0KhKRLHZK2A7YH1pD0ycKhVYDx\nLczfkl8/nF/PyK8HklZoG67eNwJvAtaSVFwIbRXS8gLD2R4AvBNYX9KMwqGVgX+3aHPtGu8nTQhb\nHdgAWBs4hQZSEAWbTj6rTuqt/FkVeDEwU9L1wKnAhS6XyfID4DPA9yGtESTpp8B/trCr/N3IXCTp\n08DZFMRandY76nqbJb0YWAuYIGlLeE6UaxVgxeEq69C20+/U61hS1v2NDcq60t6gMeFYlmQ5YCXS\nZ1N8cn4M2LehRcb23yB12W0Xu+1HSroKOHYY8/tJq13uSVq0rMY84BMt2nw18ADwAuDrdbZle0of\nBrYBrgWwfYekYRcEooPPqsN6O/msyPV8QdIXgdcDhwDflvQz4H9s/3UY0xVtX1cn9NjSmXX43QB4\nb379cKHMwEtb1U21Nr+B1Ntdm6RQXmMe8B8jaFvpOyXpg8CHgJfW9QBXBq5qo71fZ5FjeaxEe4NG\n9FpTpl83YL0ObOcAOxT2twfmlLRdtkf3e21+vSG/LgPc1O5nRRpeXWWU6u34swK2AL4J/Jm0RMMN\nwFeHOf+3pJ7V9Xl/X+C3o/Hd6OAeK7cZeFsH9XZiu16b569KWkH2TGC9wrb6aLQ3tsW36LE0Z3lJ\n00hf1uc+J5dT+jwUOFXSqnl/LoueOFsxSdLxwMbAc1rktls+mUp6K3ACaelR5c22VylR72WS/oM0\nHPA60tPfb0q2+XhJh5NW8ZwNrCrpG7ZPHOF6t5F0DOkHZBkW3W+Zz+qjpJjUQ8APgc/YflbSOOAO\n0to/jfgwaeLcRpL+AdxNGs4qS6XvhqRlgQ+SluoGuBT4vu1nS9TZSZvPk/ROlvx/0KqHBXCxpG8U\n2nwZcKztR5sZKC0kZeBRSvY+c3sezTYHlLUp1Pme/Papdm2DxsQEySYoLVJ2CumHcmGt3PbspkZL\nXmMV0mfc9D9SA5srgaOBk4A9SMM0sn10Cds7gT1s/6lsfQXbcaQfvdeTfqAvBH7oEl8QSXNsT5Z0\nIGlF0P8HzLbdcrXPDuv9M+nHp/5v1DKuJOlY0rDX3xoce2Wzz1DS+rbvlvQ8YJztebWyVnXWXaet\n74akH5JWWD0tF70bWGj7fSVsK7dZ0gWkH+z6z/jrTY0W2f6CtChUsc1b2H7rMDavyW+fsV06cC7p\nbpJDetD2tmXtsm3t/9Y8298Y9uSgFOFYmiBptu2tK9quSnIOpZ/U6uuVdLPtzXLZFbZ3LGF7lRcf\nv2+nzfsA59ueX8H2VmAy8FPg27Yvk3Sj7S1K2D4PeNr2wrw/HljedsuAtqRr2/0RqbPfCtiB9IN0\nle3rS9hcb3ururK2viuS3gxswuI90mF7AI0+zzY+48ptlnSL7U1bndfEdo7tya3KgrFHDIU15zeS\nPkRarvO5H1uXy8I5lfSkVpt78G7S6mxNn9QKPF0bjpF0BPAP0tBWGWZJOhv4dV2bf1nCdk/gm5Iu\nB84iZUmVzbD6PnAPcCNwuaT1SIHPMlwM7AbUVqSbAPyOFHtoSHYIAJdIOhH4JYvfbxkH8UXS36f2\n2fxI0s9tN8yUkrQRyRmsmocca6xCwUGUqPcUUqbRa0lDcPtSbrnthZI2cE4skPRSCj2IEWzz1ZI2\ns31zyfOLPCVpB9tX5va8mpLDTfncY6g2zLlWwQ6S4eUl7NYA3s+Sw35lh7GDTPRYmpC71vWU/WJX\nflKTNBX4EzAR+DLpR+BE29eUsP1RkzaX+o+Rx/HfCOxPepK/qMxQS5NrLVPGMVX5rCRdMswlXSYO\nJulPwJa2n877E0jB7Vc2OX8v0nrfe5LWEK8xDzjL9tWt6szXucn25oXXlYBf2n59C7tdSQ8nd5F+\nZNcDDrHd9LPoRpsl3Qa8jBSXmc+iH/gyw5yTScNgtXjSI8BBtltmKlYd5lSas7I/cFvBzrb3LFHn\n1cAVDer8RSvbYHGix9IE2+t3YF75Sc32zGxj24e0U2m75zewf1bSb0lDQxOAvchLlw6HpBcB/wW8\nxPYbJW0MbAf8T4lqn5C0Va2XIWlrWnxWtl9b4rqtuIf01F5bcH15oGmase1zgXMlbdfO2H8Davf2\npKSXkOYZtfyu2b5Y0obAK0g/7n9uNWzZpTa/saIdpAekr5Iy0iaSYjV7Uy4F/lHbv61Q597AK6oM\n6ZLSspvOdwnKE46lCZJWBD4JrGv7sNp/atvnlTD/IHBajrUIeJjGs+Ib1Vv7QV4JWFfSFsAHbH+o\nhO3LSSmzL7K9qaTNgT2bDe/U2e4OvIM0RHMpaZimrIzIdNLT9Ofz/u2kiXxlHMvHgZ9Luj/vr0l6\n4myJFp9AV+NRUuLAnBbm84FbJV1EcqSvA65UnnBp+6NN7PbJMaWngAtI6cofd1ozvAznSZpI+sGt\nJYL8sJVR7k1+gEJWmKSyWWE3SPowS8Z1mvZkJa1i+zFS76Yq55Ky3q4nDem2Q9VhzrtISQ5VHMt5\nkt5k+/wKtkGBGAprQo5VzAbek3+kJwB/bCfwmDN/yP9By9pcSxp3n2F7y1xWKoAq6TLyDOsKtmeR\nYiu/bfdpT9JM21Ml3VCot3SQNv9oFp/Ey/xYojR7fAqL0pPfDMwENgJ+bvurw9gO6+htn9aoXIsy\n4PYhPR1/ArikTBA9208gPXjsSHJoVwDfqw3JDWPXSVbYz0nzdN5Jmoh5IPAn20115CSdZ/sthWyr\n4uzKskPCnQT+Gw3xtRzmVMpE24IUuys6pGYPCkXbecDzst2ztJeuHxSIHktzNrC9v5JcCrafkhaf\nutwM1WWF5R/8Ullhua5766oaNkhboNKs8FznO/KQ1uuy/XW2/1Wy3ickPZ/0A4SkV5F6Dk2RtIvt\nP9QFlQE2lFQ24eD5wFa2H8/XPBo4h/S5zyb1Chpi+zRJy5GckIG/2H6mRJ3L5tc3AWfafrjk16LG\naaReQE2K5gDgdFr3DqfWOa8/KKXEl+FltveTtFe+75+S0rqbYvst+bWTIeHKgf8OhjtnsHg8qZ06\ny2rUBS0Ix9KcZ/LTZe3HcgPKd687yQq7V9L2gPMP30dJY9VleCi3s9bmfUlSLy1RUgX+GmkYTMDJ\nkj5j+5wS5p8k/Wd+qZI8yRq0lnR5DfAH0lwdam3OdZtF2VrDsS5QdAbPkmZsPyVp2L+VpDeRstn+\nmutcX9IHSozr/yYHlp8CPpQziYbtbdTxijoHcUlJB9F2VliBWg9wrqRNgf8jZT6VQtKeFIbgSg4H\nQ0oAOTj3etoN/FdK2S/2NJVERtdplSygRVmGza7ZMsswqMN9MP2/HzfSmPtlwIPAT0jB3p1L2i4h\n0dGorIntC3J9/wT+BfwYeH5J25cCvyeJGv4DuBKYVNL2RuCFhf01gBtL2q4AfBq4iOQQPgOs0Ibt\ngaT4zNF5O6qk7RdJ4/c1u1nAUaThjJ+0sP0z6Um+tr8BaRiuTL2rAePz+xWBF7fxvZoOvKqwvy3w\n3RJ2uwJ/Jzn+S/P38bUl63xfbvNOpBjEv0hxuzK2XyENK703bxcBx5e0Xa/RVtL2F8CX8nf6pfnv\n+8sSdpeSMilXz5/XbOAbLWwuydsfSU54VrZ7Friy7N82tkVbxFiGIQ/vvIr0pHWN7YdK2v2RJBFS\nzAr7mu3tWtiNBz5q+6QO2/3cDOs2bJ6bkJn3x5Ecy2bDmNXO/Rlp3spPctEBwGq2W66NojSzuxbg\nLaaHlpoBnbPIdiD9ja60Pauk3eW2dyrsC7isWDaM7aYsKblzegubm0k9sVo86e95fz3gNreIRUha\nAfgUi1SfLwJOcovYTLZdHngbqZdSG8qzS8iyKAk6TnaS7q99R29wiV5HJzSK0ZWJ29XifJLeR+qt\nHK2c2l2izrOA45yH7vLf+dO2D65+J0snMRQ2PGuRpLqXAXZqY+z/cOB0LdKDeoQSWWG2FyrNPWjL\nsTTJjqI29l/yR/oCSReSRPwgZWaVzY6pOrwDsLbt3UueCyzKWJK0Oml+xd2FY6u73CTWWyWdD/yM\n9AO/H0lG/63QfFJpjuPsTHIs55PSca8kxUmG4y0tjrfidJLz/nLeP4AkvV9mYbNzWSTLUiVbaiIp\nsxEWzUkZaaqm7C8jaU3SMPTnW51cx0YuxINs36I0Fydok3AsTZB0KrA5cCswlIvLjv3vSgrSrpT3\nHwemShrn1mmwV0n6NkuuuzHcOG/HQUfbn5H0NuDVpKf/abZ/VdL8Bkmvcp7EKWlbWkuV16gS4P2p\npD1IApL3FMpr8ZkyUvIrkIYba9pUD5KGT/Zg+L/zvqSsoxtsH5ITHlqmC7uBJlmbjKrzLnA86e97\nCenz3YnyC891QqWHM1LW24UkiZ6ZORZ1R8k6/5Sz735M+g68i/LxzaBADIU1QdJttjeuaFtLg51B\n+s/YThpsLc1ysWC2y6kqjyqdDu/ka3Qys3sJDayRRotSq2eT5vzMA26xvckI1zsdOKXOeR/kcvOb\npgEnt+m8i/ZrAlPz7nW2/6/KdUrWVex9ixQvg/SQVXqItGLdK7C4gvTllEgFD5YkeizN+aOkjW3f\nVsG2choscB6Lzxsw8Jikyc16O1p8FcUl8DA5/Dl3v9HTRZkc/k6Hd6Czmd1XS5rqrFbQDvlH5FDa\nmDSYmak0wfEHpL/l45TT+uqUbYH3SPp73l+X9IR9M00cccHxLwMcIuku2nTeme1YJNY5nqSfN1LU\net+vIDmzc0ntfRfph35Y1MEk4exATqLNoehgSaLH0gRJO5Em3v0f7T9J/4kkD/5M3l+elBX2ShUm\nETaxbbu3o4qT/Qad3Nt5OfA30hNtO3+jticNZrszSD9wV5DSjFdxCe2rTlES9mxKo6G2KjYNrvFd\nUo+yGHv7q+0PN7fqHEm/Iy28NS/vr0z6/g87pKcKk4QLDrghI52oMBaJHktzTiXNP7mZRTGWsvwU\nuEbSuXl/D+DMnK3VqgfUdm+n3nFIep7tJ+rPG4N00ttpe9Jg5kekp/eTSbGcOTnD7L87aEtLqsRo\nuhDXgRSD2tT5CVTSaaT/EyNN/RylZyg396bKJOFu9LyDAuFYmvN321Vn8H45ZxzV0mAPL6TBtlq5\nr5NJf5V1xgaRDn84K00adFILuIw0TPNaUpB5E2BEHUsP+QvpO1n7rNehnIhkp5wBXCfpV6TexD4s\nkrMZjrYnCXfJAQcFwrE058/5KfY3tL+2CU4rTZZebbJAJ72dbwJvIEta2L4xD+kFSzJNaWb2F0if\n10qkCZfDIuliUkD5j6ThsKkuL30ziDyfFMupxZGmkuKPte9YSzn6Ktg+Tklpu7bA3SG2byhhWnkZ\n5rp443KkpJQnWsQZgwZEjKUJ6nBtkw7rrjrp71rb22pxMchSqwwubVSdNCjpJNLyy/NJKdWXk8RJ\nx+R66Vq0VHBDbF82Wm1pB1WYJNzgGnsD29j+j+61bOkgeixNcIdrm3RYd9XeTic6Y0sblSYN2v4E\ngNICXYeQYi4vJq3nMuZwWmb6xcA2pKf5mSOZbtwp6lAAtojtX0s6sstNXCoIx1KHpM/a/qqkk2mQ\nKTJc6m4fcDhprH8t4D7SEr8jmr0zwFSaNKi0XPSOpF7L30hJHld0uW19g5I0ylEkwdCaOOmxtk/t\nbcuaUlkAVosrbY8jZWfGkE4FwrEsSe0Jv9TwUz/hpGVWajw5qCzpPgH4BmkxsVJLEgw4nyEt4fxv\neE4/72rSD3g/soHttxX2vySpldpFjT0K7xeQVB326lbDlibCsdRhu7Zo1JO2f148piQt37fkVNCP\n2Z6b91cDvj4acaFBodNJg7ZPHPlW9hX3sfgqkvOAe3vUljJ0six4z4a/xxoRvG9CI7mQXkiItEOj\nyZetJmQubXRj0uDShKTTgc1IMSmTnuCvIy0/XVbgdNTIKfans0gs8xGS9E3LFGlJa5PmJ72adK9X\nkh7U7huh5o5ZosdSh6Q3klYHXKtOKmUVSq7G2EPGSVrN9iOQlH6Jv/FihONom7/mrUYtDb6vVlus\n0xg7ncU1xnaj3NybH5HS/WsjE+/KZa/rUjOXGuJHZ0nuJ8VX9mTxzKx5pPXN+5mvk2IH55CeuN4O\nHNfbJgWDjO0v9boNJelIYyyzhu3iNIPpkj7evSYuPcRQWBMkLWv72dZn9heSNiHNCBdwcUURzSAA\nQGnp5c+ypFhn36ltQ3WNsXzu70krfNZ00Q4gTczctalR0JBxvW5AH7ONpIsk3S7pLkl350Bv3yJp\nN9u32v627ZNt39ZKoDIIWvATkljn+qSlgu8hiaL2K1U1xiAtvfx2krzPA6S1dyKgX4HosTRB0p9J\nQ1+zWbRkLrW0y35E0uWkhck+RRoa+CEw3/a+PW1YMLBImm17axWW95V0me1hZ+T3CkmfJzmHosbY\n2baPL2F7GvDxuhjl1yKrsn0ixtKcR23/tteNaJPXkJxKbWXBo2yfOcz5QdCK2nDwA5LeTIpBrt3D\n9gxLBxpjAJvXnEq+1sOSIqOyAuFYmnOJpBNJS9QWRSiHWyK416xGWhDqr6T//OtJkqNbGlTnP7NM\nyqdIqbir0OdJLPn/aIQSaTMAAAKDSURBVJX/p5FV2SViKKwJWrREcBH3a9ASQNLtwFdsnyppAnAC\nMMX29j1uWhD0PZLeA3yOtP7Rc1mVts/oacMGkHAsYwhJ65KGw9a3fWzen2S7bLplECyGpK8C/0ma\nvX4BsAUpDvHjnjZshJC0MbALkVXZEeFYmiDpRcB/AS+x/cb8hdvO9v/0uGlNkfQ90mqXuzgtg7wa\n8DvbU3vctGBAkTTH9mRJ+wB7k4bBLomlGILhiHTj5kwnLVX7krx/O9Dvk6W2dVqL/GmAPFa8XG+b\nFAw4tbVq3gScafvhXjYmGAzCsTTnBbZ/Rl7vPivZLhzepOc8K2k8i5ZlXYPc/iCoyG9y6v0U4OL8\nnXq6x20K+pxwLM15IkuE136kX0VaGKqf+RYpf/+Fko4jiej9V2+bFAwyto8EtiMlgTxL0t4KKflg\nWCLG0gRJW5HSKzclLRy0BrBvGZXUXiJpI2BXFgUfYwXJoG0k7WL7D3WLXz2H7V+OdpuCwSFytJuz\nAfBGYB3S2ujbMgCfl+0/kyQ4gqATdiKtGrkHqdeuutdwLEFT+v6Hsod80fbPc2bVbiTl4O+RHEwQ\njHXmZSn6W1jkUCCW6g1KEDGW5tQC9W8GTrF9LpFhFSw9rETSm9sa+CCwJilD8nBg4x62KxgAIsbS\nBEnnAf8g9Va2Jk0Quy7y94OliU5k6IOll+ixNOftpHksu+c15FcHPtPbJgXBqNOJDH2wlBIxlibY\nfpJCgNL2A6Q1GoJgaeIM4DpJRRn603rbpKDfiaGwIAiGJafe12ToL29Dhj5YSgnHEgRBEHSViLEE\nQRAEXSUcSxAEQdBVwrEEQRAEXSUcSxAEQdBVwrEEQRAEXeX/A50Zr0StNQOvAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a11807710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(model1.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>good</th>\n",
       "      <th>great</th>\n",
       "      <th>excellent</th>\n",
       "      <th>love</th>\n",
       "      <th>best</th>\n",
       "      <th>nice</th>\n",
       "      <th>right</th>\n",
       "      <th>happy</th>\n",
       "      <th>waste</th>\n",
       "      <th>bad</th>\n",
       "      <th>poor</th>\n",
       "      <th>hate</th>\n",
       "      <th>disappoint</th>\n",
       "      <th>not</th>\n",
       "      <th>don't</th>\n",
       "      <th>doesn't</th>\n",
       "      <th>couldn't</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sentiment</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.185851</td>\n",
       "      <td>0.289086</td>\n",
       "      <td>0.154154</td>\n",
       "      <td>0.156736</td>\n",
       "      <td>0.122626</td>\n",
       "      <td>0.143662</td>\n",
       "      <td>-0.018488</td>\n",
       "      <td>0.069525</td>\n",
       "      <td>-0.127708</td>\n",
       "      <td>-0.119339</td>\n",
       "      <td>-0.131705</td>\n",
       "      <td>-0.051899</td>\n",
       "      <td>-0.146681</td>\n",
       "      <td>-0.277991</td>\n",
       "      <td>-0.100759</td>\n",
       "      <td>-0.095813</td>\n",
       "      <td>-0.000101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>good</th>\n",
       "      <td>0.185851</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.042877</td>\n",
       "      <td>-0.000633</td>\n",
       "      <td>0.004917</td>\n",
       "      <td>-0.016868</td>\n",
       "      <td>0.079341</td>\n",
       "      <td>0.003456</td>\n",
       "      <td>0.021256</td>\n",
       "      <td>-0.036348</td>\n",
       "      <td>-0.033966</td>\n",
       "      <td>-0.037486</td>\n",
       "      <td>-0.022146</td>\n",
       "      <td>0.011212</td>\n",
       "      <td>0.014900</td>\n",
       "      <td>-0.046572</td>\n",
       "      <td>-0.036348</td>\n",
       "      <td>0.047671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>great</th>\n",
       "      <td>0.289086</td>\n",
       "      <td>-0.042877</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.054967</td>\n",
       "      <td>-0.007788</td>\n",
       "      <td>-0.026558</td>\n",
       "      <td>0.058145</td>\n",
       "      <td>-0.036365</td>\n",
       "      <td>-0.043393</td>\n",
       "      <td>-0.042076</td>\n",
       "      <td>-0.039318</td>\n",
       "      <td>-0.043393</td>\n",
       "      <td>-0.025636</td>\n",
       "      <td>-0.048327</td>\n",
       "      <td>-0.086853</td>\n",
       "      <td>-0.053911</td>\n",
       "      <td>-0.042076</td>\n",
       "      <td>0.000643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>excellent</th>\n",
       "      <td>0.154154</td>\n",
       "      <td>-0.000633</td>\n",
       "      <td>-0.054967</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.026149</td>\n",
       "      <td>-0.025010</td>\n",
       "      <td>-0.026149</td>\n",
       "      <td>-0.018377</td>\n",
       "      <td>-0.021929</td>\n",
       "      <td>-0.021263</td>\n",
       "      <td>-0.019870</td>\n",
       "      <td>-0.021929</td>\n",
       "      <td>-0.012955</td>\n",
       "      <td>-0.024422</td>\n",
       "      <td>-0.064178</td>\n",
       "      <td>-0.027245</td>\n",
       "      <td>-0.021263</td>\n",
       "      <td>-0.016759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>love</th>\n",
       "      <td>0.156736</td>\n",
       "      <td>0.004917</td>\n",
       "      <td>-0.007788</td>\n",
       "      <td>-0.026149</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.023543</td>\n",
       "      <td>-0.024615</td>\n",
       "      <td>-0.017300</td>\n",
       "      <td>-0.020643</td>\n",
       "      <td>-0.020016</td>\n",
       "      <td>-0.018705</td>\n",
       "      <td>-0.020643</td>\n",
       "      <td>-0.012196</td>\n",
       "      <td>-0.022990</td>\n",
       "      <td>-0.060414</td>\n",
       "      <td>-0.025647</td>\n",
       "      <td>-0.020016</td>\n",
       "      <td>-0.015776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>best</th>\n",
       "      <td>0.122626</td>\n",
       "      <td>-0.016868</td>\n",
       "      <td>-0.026558</td>\n",
       "      <td>-0.025010</td>\n",
       "      <td>-0.023543</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.023543</td>\n",
       "      <td>-0.016546</td>\n",
       "      <td>-0.019744</td>\n",
       "      <td>-0.019145</td>\n",
       "      <td>-0.017890</td>\n",
       "      <td>-0.019744</td>\n",
       "      <td>-0.011664</td>\n",
       "      <td>-0.021989</td>\n",
       "      <td>-0.017103</td>\n",
       "      <td>-0.024530</td>\n",
       "      <td>-0.019145</td>\n",
       "      <td>-0.015089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nice</th>\n",
       "      <td>0.143662</td>\n",
       "      <td>0.079341</td>\n",
       "      <td>0.058145</td>\n",
       "      <td>-0.026149</td>\n",
       "      <td>-0.024615</td>\n",
       "      <td>-0.023543</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.042708</td>\n",
       "      <td>-0.020643</td>\n",
       "      <td>-0.020016</td>\n",
       "      <td>0.036908</td>\n",
       "      <td>-0.020643</td>\n",
       "      <td>-0.012196</td>\n",
       "      <td>-0.022990</td>\n",
       "      <td>-0.040920</td>\n",
       "      <td>-0.025647</td>\n",
       "      <td>-0.020016</td>\n",
       "      <td>-0.015776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>right</th>\n",
       "      <td>-0.018488</td>\n",
       "      <td>0.003456</td>\n",
       "      <td>-0.036365</td>\n",
       "      <td>-0.018377</td>\n",
       "      <td>-0.017300</td>\n",
       "      <td>-0.016546</td>\n",
       "      <td>0.042708</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.014508</td>\n",
       "      <td>-0.014067</td>\n",
       "      <td>-0.013146</td>\n",
       "      <td>-0.014508</td>\n",
       "      <td>-0.008571</td>\n",
       "      <td>-0.016157</td>\n",
       "      <td>0.012343</td>\n",
       "      <td>-0.018024</td>\n",
       "      <td>-0.014067</td>\n",
       "      <td>-0.011088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>happy</th>\n",
       "      <td>0.069525</td>\n",
       "      <td>0.021256</td>\n",
       "      <td>-0.043393</td>\n",
       "      <td>-0.021929</td>\n",
       "      <td>-0.020643</td>\n",
       "      <td>-0.019744</td>\n",
       "      <td>-0.020643</td>\n",
       "      <td>-0.014508</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.016786</td>\n",
       "      <td>-0.015686</td>\n",
       "      <td>-0.017312</td>\n",
       "      <td>-0.010228</td>\n",
       "      <td>-0.019280</td>\n",
       "      <td>-0.004505</td>\n",
       "      <td>-0.021508</td>\n",
       "      <td>-0.016786</td>\n",
       "      <td>-0.013230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>waste</th>\n",
       "      <td>-0.127708</td>\n",
       "      <td>-0.036348</td>\n",
       "      <td>-0.042076</td>\n",
       "      <td>-0.021263</td>\n",
       "      <td>-0.020016</td>\n",
       "      <td>-0.019145</td>\n",
       "      <td>-0.020016</td>\n",
       "      <td>-0.014067</td>\n",
       "      <td>-0.016786</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.015210</td>\n",
       "      <td>-0.016786</td>\n",
       "      <td>-0.009917</td>\n",
       "      <td>-0.018695</td>\n",
       "      <td>-0.049127</td>\n",
       "      <td>0.179475</td>\n",
       "      <td>-0.016277</td>\n",
       "      <td>-0.012829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bad</th>\n",
       "      <td>-0.119339</td>\n",
       "      <td>-0.033966</td>\n",
       "      <td>-0.039318</td>\n",
       "      <td>-0.019870</td>\n",
       "      <td>-0.018705</td>\n",
       "      <td>-0.017890</td>\n",
       "      <td>0.036908</td>\n",
       "      <td>-0.013146</td>\n",
       "      <td>-0.015686</td>\n",
       "      <td>-0.015210</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.015686</td>\n",
       "      <td>-0.009267</td>\n",
       "      <td>-0.017470</td>\n",
       "      <td>0.030274</td>\n",
       "      <td>0.033998</td>\n",
       "      <td>-0.015210</td>\n",
       "      <td>-0.011988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poor</th>\n",
       "      <td>-0.131705</td>\n",
       "      <td>-0.037486</td>\n",
       "      <td>-0.043393</td>\n",
       "      <td>-0.021929</td>\n",
       "      <td>-0.020643</td>\n",
       "      <td>-0.019744</td>\n",
       "      <td>-0.020643</td>\n",
       "      <td>-0.014508</td>\n",
       "      <td>-0.017312</td>\n",
       "      <td>-0.016786</td>\n",
       "      <td>-0.015686</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.010228</td>\n",
       "      <td>-0.019280</td>\n",
       "      <td>-0.050665</td>\n",
       "      <td>-0.021508</td>\n",
       "      <td>-0.016786</td>\n",
       "      <td>-0.013230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hate</th>\n",
       "      <td>-0.051899</td>\n",
       "      <td>-0.022146</td>\n",
       "      <td>-0.025636</td>\n",
       "      <td>-0.012955</td>\n",
       "      <td>-0.012196</td>\n",
       "      <td>-0.011664</td>\n",
       "      <td>-0.012196</td>\n",
       "      <td>-0.008571</td>\n",
       "      <td>-0.010228</td>\n",
       "      <td>-0.009917</td>\n",
       "      <td>-0.009267</td>\n",
       "      <td>-0.010228</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.078920</td>\n",
       "      <td>-0.029932</td>\n",
       "      <td>-0.012707</td>\n",
       "      <td>-0.009917</td>\n",
       "      <td>-0.007816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disappoint</th>\n",
       "      <td>-0.146681</td>\n",
       "      <td>0.011212</td>\n",
       "      <td>-0.048327</td>\n",
       "      <td>-0.024422</td>\n",
       "      <td>-0.022990</td>\n",
       "      <td>-0.021989</td>\n",
       "      <td>-0.022990</td>\n",
       "      <td>-0.016157</td>\n",
       "      <td>-0.019280</td>\n",
       "      <td>-0.018695</td>\n",
       "      <td>-0.017470</td>\n",
       "      <td>-0.019280</td>\n",
       "      <td>0.078920</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.056426</td>\n",
       "      <td>-0.023954</td>\n",
       "      <td>0.036889</td>\n",
       "      <td>-0.014735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>not</th>\n",
       "      <td>-0.277991</td>\n",
       "      <td>0.014900</td>\n",
       "      <td>-0.086853</td>\n",
       "      <td>-0.064178</td>\n",
       "      <td>-0.060414</td>\n",
       "      <td>-0.017103</td>\n",
       "      <td>-0.040920</td>\n",
       "      <td>0.012343</td>\n",
       "      <td>-0.004505</td>\n",
       "      <td>-0.049127</td>\n",
       "      <td>0.030274</td>\n",
       "      <td>-0.050665</td>\n",
       "      <td>-0.029932</td>\n",
       "      <td>-0.056426</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.006700</td>\n",
       "      <td>-0.001571</td>\n",
       "      <td>0.051237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>don't</th>\n",
       "      <td>-0.100759</td>\n",
       "      <td>-0.046572</td>\n",
       "      <td>-0.053911</td>\n",
       "      <td>-0.027245</td>\n",
       "      <td>-0.025647</td>\n",
       "      <td>-0.024530</td>\n",
       "      <td>-0.025647</td>\n",
       "      <td>-0.018024</td>\n",
       "      <td>-0.021508</td>\n",
       "      <td>0.179475</td>\n",
       "      <td>0.033998</td>\n",
       "      <td>-0.021508</td>\n",
       "      <td>-0.012707</td>\n",
       "      <td>-0.023954</td>\n",
       "      <td>-0.006700</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.029227</td>\n",
       "      <td>-0.016437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doesn't</th>\n",
       "      <td>-0.095813</td>\n",
       "      <td>-0.036348</td>\n",
       "      <td>-0.042076</td>\n",
       "      <td>-0.021263</td>\n",
       "      <td>-0.020016</td>\n",
       "      <td>-0.019145</td>\n",
       "      <td>-0.020016</td>\n",
       "      <td>-0.014067</td>\n",
       "      <td>-0.016786</td>\n",
       "      <td>-0.016277</td>\n",
       "      <td>-0.015210</td>\n",
       "      <td>-0.016786</td>\n",
       "      <td>-0.009917</td>\n",
       "      <td>0.036889</td>\n",
       "      <td>-0.001571</td>\n",
       "      <td>0.029227</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.012829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>couldn't</th>\n",
       "      <td>-0.000101</td>\n",
       "      <td>0.047671</td>\n",
       "      <td>0.000643</td>\n",
       "      <td>-0.016759</td>\n",
       "      <td>-0.015776</td>\n",
       "      <td>-0.015089</td>\n",
       "      <td>-0.015776</td>\n",
       "      <td>-0.011088</td>\n",
       "      <td>-0.013230</td>\n",
       "      <td>-0.012829</td>\n",
       "      <td>-0.011988</td>\n",
       "      <td>-0.013230</td>\n",
       "      <td>-0.007816</td>\n",
       "      <td>-0.014735</td>\n",
       "      <td>0.051237</td>\n",
       "      <td>-0.016437</td>\n",
       "      <td>-0.012829</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            sentiment      good     great  excellent      love      best  \\\n",
       "sentiment    1.000000  0.185851  0.289086   0.154154  0.156736  0.122626   \n",
       "good         0.185851  1.000000 -0.042877  -0.000633  0.004917 -0.016868   \n",
       "great        0.289086 -0.042877  1.000000  -0.054967 -0.007788 -0.026558   \n",
       "excellent    0.154154 -0.000633 -0.054967   1.000000 -0.026149 -0.025010   \n",
       "love         0.156736  0.004917 -0.007788  -0.026149  1.000000 -0.023543   \n",
       "best         0.122626 -0.016868 -0.026558  -0.025010 -0.023543  1.000000   \n",
       "nice         0.143662  0.079341  0.058145  -0.026149 -0.024615 -0.023543   \n",
       "right       -0.018488  0.003456 -0.036365  -0.018377 -0.017300 -0.016546   \n",
       "happy        0.069525  0.021256 -0.043393  -0.021929 -0.020643 -0.019744   \n",
       "waste       -0.127708 -0.036348 -0.042076  -0.021263 -0.020016 -0.019145   \n",
       "bad         -0.119339 -0.033966 -0.039318  -0.019870 -0.018705 -0.017890   \n",
       "poor        -0.131705 -0.037486 -0.043393  -0.021929 -0.020643 -0.019744   \n",
       "hate        -0.051899 -0.022146 -0.025636  -0.012955 -0.012196 -0.011664   \n",
       "disappoint  -0.146681  0.011212 -0.048327  -0.024422 -0.022990 -0.021989   \n",
       "not         -0.277991  0.014900 -0.086853  -0.064178 -0.060414 -0.017103   \n",
       "don't       -0.100759 -0.046572 -0.053911  -0.027245 -0.025647 -0.024530   \n",
       "doesn't     -0.095813 -0.036348 -0.042076  -0.021263 -0.020016 -0.019145   \n",
       "couldn't    -0.000101  0.047671  0.000643  -0.016759 -0.015776 -0.015089   \n",
       "\n",
       "                nice     right     happy     waste       bad      poor  \\\n",
       "sentiment   0.143662 -0.018488  0.069525 -0.127708 -0.119339 -0.131705   \n",
       "good        0.079341  0.003456  0.021256 -0.036348 -0.033966 -0.037486   \n",
       "great       0.058145 -0.036365 -0.043393 -0.042076 -0.039318 -0.043393   \n",
       "excellent  -0.026149 -0.018377 -0.021929 -0.021263 -0.019870 -0.021929   \n",
       "love       -0.024615 -0.017300 -0.020643 -0.020016 -0.018705 -0.020643   \n",
       "best       -0.023543 -0.016546 -0.019744 -0.019145 -0.017890 -0.019744   \n",
       "nice        1.000000  0.042708 -0.020643 -0.020016  0.036908 -0.020643   \n",
       "right       0.042708  1.000000 -0.014508 -0.014067 -0.013146 -0.014508   \n",
       "happy      -0.020643 -0.014508  1.000000 -0.016786 -0.015686 -0.017312   \n",
       "waste      -0.020016 -0.014067 -0.016786  1.000000 -0.015210 -0.016786   \n",
       "bad         0.036908 -0.013146 -0.015686 -0.015210  1.000000 -0.015686   \n",
       "poor       -0.020643 -0.014508 -0.017312 -0.016786 -0.015686  1.000000   \n",
       "hate       -0.012196 -0.008571 -0.010228 -0.009917 -0.009267 -0.010228   \n",
       "disappoint -0.022990 -0.016157 -0.019280 -0.018695 -0.017470 -0.019280   \n",
       "not        -0.040920  0.012343 -0.004505 -0.049127  0.030274 -0.050665   \n",
       "don't      -0.025647 -0.018024 -0.021508  0.179475  0.033998 -0.021508   \n",
       "doesn't    -0.020016 -0.014067 -0.016786 -0.016277 -0.015210 -0.016786   \n",
       "couldn't   -0.015776 -0.011088 -0.013230 -0.012829 -0.011988 -0.013230   \n",
       "\n",
       "                hate  disappoint       not     don't   doesn't  couldn't  \n",
       "sentiment  -0.051899   -0.146681 -0.277991 -0.100759 -0.095813 -0.000101  \n",
       "good       -0.022146    0.011212  0.014900 -0.046572 -0.036348  0.047671  \n",
       "great      -0.025636   -0.048327 -0.086853 -0.053911 -0.042076  0.000643  \n",
       "excellent  -0.012955   -0.024422 -0.064178 -0.027245 -0.021263 -0.016759  \n",
       "love       -0.012196   -0.022990 -0.060414 -0.025647 -0.020016 -0.015776  \n",
       "best       -0.011664   -0.021989 -0.017103 -0.024530 -0.019145 -0.015089  \n",
       "nice       -0.012196   -0.022990 -0.040920 -0.025647 -0.020016 -0.015776  \n",
       "right      -0.008571   -0.016157  0.012343 -0.018024 -0.014067 -0.011088  \n",
       "happy      -0.010228   -0.019280 -0.004505 -0.021508 -0.016786 -0.013230  \n",
       "waste      -0.009917   -0.018695 -0.049127  0.179475 -0.016277 -0.012829  \n",
       "bad        -0.009267   -0.017470  0.030274  0.033998 -0.015210 -0.011988  \n",
       "poor       -0.010228   -0.019280 -0.050665 -0.021508 -0.016786 -0.013230  \n",
       "hate        1.000000    0.078920 -0.029932 -0.012707 -0.009917 -0.007816  \n",
       "disappoint  0.078920    1.000000 -0.056426 -0.023954  0.036889 -0.014735  \n",
       "not        -0.029932   -0.056426  1.000000 -0.006700 -0.001571  0.051237  \n",
       "don't      -0.012707   -0.023954 -0.006700  1.000000  0.029227 -0.016437  \n",
       "doesn't    -0.009917    0.036889 -0.001571  0.029227  1.000000 -0.012829  \n",
       "couldn't   -0.007816   -0.014735  0.051237 -0.016437 -0.012829  1.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = model1[positive_keywords + negative_keywords + negating_keywords]\n",
    "target = model1['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 999 points : 279\n"
     ]
    }
   ],
   "source": [
    "# Our data is binary / boolean, so we're importing the Bernoulli classifier.\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "# Instantiate our model and store it in a new variable.\n",
    "bnb = BernoulliNB()\n",
    "\n",
    "# Fit our model to the data.\n",
    "bnb.fit(data, target)\n",
    "\n",
    "# Classify, storing the result in a new variable.\n",
    "y_pred = bnb.predict(data)\n",
    "\n",
    "# Display our results.\n",
    "print(\"Number of mislabeled points out of a total {} points : {}\".format(\n",
    "    data.shape[0],\n",
    "    (target != y_pred).sum()\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[486, 266],\n",
       "       [ 13, 234]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "pp = confusion_matrix(y_pred, target, labels=[0,1])\n",
    "pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sensitivity of our model is 0.95%\n",
      "The specificity of our model is 0.65%\n"
     ]
    }
   ],
   "source": [
    "print ('The sensitivity of our model is {:.2f}%'.format(pp[1][1]/sum(pp[1])))\n",
    "print ('The specificity of our model is {:.2f}%'.format(pp[0][0]/sum(pp[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function for Testing Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function for running Naive Bayes using Cross Validation (n=4)\n",
    "\n",
    "def naive_bayes_cross_validation (test_features):\n",
    "    \n",
    "    # Matrix of predictive features (df) --> Printed text\n",
    "    \n",
    "    # Create 4 holdout groups\n",
    "    holdouts = [test_features.iloc[int(len(test_features)*(i/4)):int(len(test_features)*((i+1)/4))] for i in range(4)]\n",
    "    \n",
    "    #Run Naive Bayes on each holdout, printing results\n",
    "    for holdout in holdouts:\n",
    "        training_set = test_features[~test_features.index.isin(holdout.index)]\n",
    "\n",
    "        #Seperate out target & data for training set and holdout\n",
    "        target = training_set['sentiment']\n",
    "        data = training_set.iloc[:,2:]\n",
    "        \n",
    "        holdout_target = holdout['sentiment']\n",
    "        holdout_data = holdout.iloc[:,2:]\n",
    "    \n",
    "        #Run Test\n",
    "        from sklearn.naive_bayes import BernoulliNB\n",
    "        bnb = BernoulliNB()\n",
    "        bnb.fit(data, target)\n",
    "\n",
    "        #Make predictions using holdout group\n",
    "        y_pred = bnb.predict(holdout_data)\n",
    "        pp = confusion_matrix(y_pred, holdout_target, labels=[0,1])\n",
    "        \n",
    "        #Print results:\n",
    "        print('Mislabeled {} points out of {}'.format((holdout_target != y_pred).sum(), len(holdout)))\n",
    "        print('Success rate:{:.2f}%'.format((holdout_target == y_pred).sum()/(len(holdout))))\n",
    "        print('Correctly labeled: {} out of {} positive reviews'.format(pp[1][1], sum(pp[1])))\n",
    "        print('Sensitivity:{:.2f}%'.format(pp[1][1]/sum(pp[1])))\n",
    "        print('Correctly labeled: {} out of {} negative reviews'.format(pp[0][0], sum(pp[0])))\n",
    "        print('Specificity:{:.2f}%\\n'.format(pp[0][0]/sum(pp[0])))\n",
    "            \n",
    "            #mislabeled out of total + success rate\n",
    "            #false positives out of total negatives + sensitivity rate\n",
    "            #false negatives out of total positives + specificity rate \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 - First Draft\n",
      "\n",
      "Mislabeled 62 points out of 249\n",
      "Success rate:0.75%\n",
      "Correctly labeled: 69 out of 73 positive reviews\n",
      "Sensitivity:0.95%\n",
      "Correctly labeled: 118 out of 176 negative reviews\n",
      "Specificity:0.67%\n",
      "\n",
      "Mislabeled 71 points out of 250\n",
      "Success rate:0.72%\n",
      "Correctly labeled: 67 out of 71 positive reviews\n",
      "Sensitivity:0.94%\n",
      "Correctly labeled: 112 out of 179 negative reviews\n",
      "Specificity:0.63%\n",
      "\n",
      "Mislabeled 76 points out of 250\n",
      "Success rate:0.70%\n",
      "Correctly labeled: 49 out of 50 positive reviews\n",
      "Sensitivity:0.98%\n",
      "Correctly labeled: 125 out of 200 negative reviews\n",
      "Specificity:0.62%\n",
      "\n",
      "Mislabeled 73 points out of 250\n",
      "Success rate:0.71%\n",
      "Correctly labeled: 49 out of 56 positive reviews\n",
      "Sensitivity:0.88%\n",
      "Correctly labeled: 128 out of 194 negative reviews\n",
      "Specificity:0.66%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Model 1 - First Draft\\n')\n",
    "\n",
    "naive_bayes_cross_validation(model1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Iterating and Improving Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The algorithm is great at predicting positive reviews, but often (35% of the time) will label a negative review as positive. Let's update our model and add some specificity around what negating words can impact a positive keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Next iteration we will specify positive keywords as having 1 positive keyword AND not having 'not'\n",
    "\n",
    "model2 = pd.DataFrame(reviews.review)\n",
    "model2['sentiment'] = reviews.sentiment\n",
    "\n",
    "for key in positive_keywords:\n",
    "        model2[key] = (model2.review.str.contains(key, case=False) & ~(model2.review.str.contains('not', case=False)))\n",
    "        \n",
    "for key in negative_keywords:\n",
    "        model2[key] = (model2.review.str.contains(key, case=False) & ~(model2.review.str.contains('not', case=False)))\n",
    "        \n",
    "for key in negating_keywords:\n",
    "        model2[key] = model2.review.str.contains(key, case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 2 - Second Draft\n",
      "\n",
      "Mislabeled 63 points out of 249\n",
      "Success rate:0.75%\n",
      "Correctly labeled: 70 out of 76 positive reviews\n",
      "Sensitivity:0.92%\n",
      "Correctly labeled: 116 out of 173 negative reviews\n",
      "Specificity:0.67%\n",
      "\n",
      "Mislabeled 70 points out of 250\n",
      "Success rate:0.72%\n",
      "Correctly labeled: 67 out of 70 positive reviews\n",
      "Sensitivity:0.96%\n",
      "Correctly labeled: 113 out of 180 negative reviews\n",
      "Specificity:0.63%\n",
      "\n",
      "Mislabeled 78 points out of 250\n",
      "Success rate:0.69%\n",
      "Correctly labeled: 47 out of 48 positive reviews\n",
      "Sensitivity:0.98%\n",
      "Correctly labeled: 125 out of 202 negative reviews\n",
      "Specificity:0.62%\n",
      "\n",
      "Mislabeled 72 points out of 250\n",
      "Success rate:0.71%\n",
      "Correctly labeled: 50 out of 57 positive reviews\n",
      "Sensitivity:0.88%\n",
      "Correctly labeled: 128 out of 193 negative reviews\n",
      "Specificity:0.66%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Model 2 - Second Draft\\n')\n",
    "\n",
    "naive_bayes_cross_validation(model2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not much of a difference. Maybe we're too positive happy - let's remove positive keywords completely and see what happens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model3 = pd.DataFrame(reviews.review)\n",
    "model3['sentiment'] = reviews.sentiment\n",
    "        \n",
    "for key in negative_keywords:\n",
    "        model3[key] = model3.review.str.contains(key, case=False)\n",
    "        \n",
    "for key in negating_keywords:\n",
    "        model3[key] = model3.review.str.contains(key, case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mislabeled 69 points out of 249\n",
      "Success rate:0.72%\n",
      "Correctly labeled: 123 out of 188 positive reviews\n",
      "Sensitivity:0.65%\n",
      "Correctly labeled: 57 out of 61 negative reviews\n",
      "Specificity:0.93%\n",
      "\n",
      "Mislabeled 74 points out of 250\n",
      "Success rate:0.70%\n",
      "Correctly labeled: 130 out of 200 positive reviews\n",
      "Sensitivity:0.65%\n",
      "Correctly labeled: 46 out of 50 negative reviews\n",
      "Specificity:0.92%\n",
      "\n",
      "Mislabeled 89 points out of 250\n",
      "Success rate:0.64%\n",
      "Correctly labeled: 112 out of 189 positive reviews\n",
      "Sensitivity:0.59%\n",
      "Correctly labeled: 49 out of 61 negative reviews\n",
      "Specificity:0.80%\n",
      "\n",
      "Mislabeled 87 points out of 250\n",
      "Success rate:0.65%\n",
      "Correctly labeled: 110 out of 192 positive reviews\n",
      "Sensitivity:0.57%\n",
      "Correctly labeled: 53 out of 58 negative reviews\n",
      "Specificity:0.91%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "naive_bayes_cross_validation(model3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Huge difference now - we're picking up on a much higher ratio of negative reviews but the positive reviews have dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good\n",
      "1    59\n",
      "0     5\n",
      "Name: sentiment, dtype: int64\n",
      "\n",
      "\n",
      "great\n",
      "1    90\n",
      "0     4\n",
      "Name: sentiment, dtype: int64\n",
      "\n",
      "\n",
      "excellent\n",
      "1    26\n",
      "0     1\n",
      "Name: sentiment, dtype: int64\n",
      "\n",
      "\n",
      "love\n",
      "1    24\n",
      "Name: sentiment, dtype: int64\n",
      "\n",
      "\n",
      "best\n",
      "1    19\n",
      "0     1\n",
      "Name: sentiment, dtype: int64\n",
      "\n",
      "\n",
      "nice\n",
      "1    23\n",
      "Name: sentiment, dtype: int64\n",
      "\n",
      "\n",
      "right\n",
      "1    5\n",
      "0    5\n",
      "Name: sentiment, dtype: int64\n",
      "\n",
      "\n",
      "happy\n",
      "1    13\n",
      "0     2\n",
      "Name: sentiment, dtype: int64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Exploring which positive keywords are the least distinguishing\n",
    "\n",
    "for key in positive_keywords:\n",
    "    print(key)\n",
    "    print(model2.sentiment[model2[key] == True].value_counts())\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "waste\n",
      "0    16\n",
      "Name: sentiment, dtype: int64\n",
      "\n",
      "\n",
      "bad\n",
      "0    11\n",
      "Name: sentiment, dtype: int64\n",
      "\n",
      "\n",
      "poor\n",
      "0    17\n",
      "Name: sentiment, dtype: int64\n",
      "\n",
      "\n",
      "hate\n",
      "0    5\n",
      "1    1\n",
      "Name: sentiment, dtype: int64\n",
      "\n",
      "\n",
      "disappoint\n",
      "0    21\n",
      "Name: sentiment, dtype: int64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's do the same for negative keywords\n",
    "\n",
    "for key in negative_keywords:\n",
    "    print(key)\n",
    "    print(model2.sentiment[model2[key] == True].value_counts())\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not\n",
      "0    111\n",
      "1     18\n",
      "Name: sentiment, dtype: int64\n",
      "\n",
      "\n",
      "don't\n",
      "0    21\n",
      "1     5\n",
      "Name: sentiment, dtype: int64\n",
      "\n",
      "\n",
      "doesn't\n",
      "0    14\n",
      "1     2\n",
      "Name: sentiment, dtype: int64\n",
      "\n",
      "\n",
      "couldn't\n",
      "1    5\n",
      "0    5\n",
      "Name: sentiment, dtype: int64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# And finally, for negating keywords\n",
    "\n",
    "for key in negating_keywords:\n",
    "    print(key)\n",
    "    print(model2.sentiment[model2[key] == True].value_counts())\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other than 'not', the negative keywords have poor predictive power. Let's remove those keywords, while keeping a 'not' negator in the positive and negative keywords.\n",
    "\n",
    "Let's also remove 'good', 'right' and 'happy' to see if we can boost the specificity without impacting sensitivity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Next iteration we will specify positive keywords as having 1 positive keyword AND not having 'not'\n",
    "\n",
    "model4 = pd.DataFrame(reviews.review)\n",
    "model4['sentiment'] = reviews.sentiment\n",
    "\n",
    "positive_keywords.remove('good')\n",
    "positive_keywords.remove('right')\n",
    "positive_keywords.remove('happy')\n",
    "\n",
    "for key in positive_keywords:\n",
    "        model4[key] = (model4.review.str.contains(key, case=False) & ~(model4.review.str.contains('not', case=False)))\n",
    "        \n",
    "for key in negative_keywords:\n",
    "        model4[key] = (model4.review.str.contains(key, case=False) & ~(model4.review.str.contains('not', case=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mislabeled 70 points out of 249\n",
      "Success rate:0.72%\n",
      "Correctly labeled: 59 out of 61 positive reviews\n",
      "Sensitivity:0.97%\n",
      "Correctly labeled: 120 out of 188 negative reviews\n",
      "Specificity:0.64%\n",
      "\n",
      "Mislabeled 84 points out of 250\n",
      "Success rate:0.66%\n",
      "Correctly labeled: 52 out of 54 positive reviews\n",
      "Sensitivity:0.96%\n",
      "Correctly labeled: 114 out of 196 negative reviews\n",
      "Specificity:0.58%\n",
      "\n",
      "Mislabeled 93 points out of 250\n",
      "Success rate:0.63%\n",
      "Correctly labeled: 31 out of 31 positive reviews\n",
      "Sensitivity:1.00%\n",
      "Correctly labeled: 126 out of 219 negative reviews\n",
      "Specificity:0.58%\n",
      "\n",
      "Mislabeled 85 points out of 250\n",
      "Success rate:0.66%\n",
      "Correctly labeled: 32 out of 34 positive reviews\n",
      "Sensitivity:0.94%\n",
      "Correctly labeled: 133 out of 216 negative reviews\n",
      "Specificity:0.62%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "naive_bayes_cross_validation(model4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still not better than our original model. Yike. Let's try one last thing - adding an all caps feature to the original model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model1a = pd.DataFrame(reviews.review)\n",
    "model1a['sentiment'] = reviews.sentiment\n",
    "\n",
    "for key in positive_keywords:\n",
    "        model1a[key] = model1a.review.str.contains(key, case=False)\n",
    "        \n",
    "for key in negative_keywords:\n",
    "        model1a[key] = model1a.review.str.contains(key, case=False)\n",
    "        \n",
    "for key in negating_keywords:\n",
    "        model1a[key] = model1a.review.str.contains(key, case=False)\n",
    "\n",
    "model1a['allcaps'] = model1a.review.str.isupper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mislabeled 62 points out of 249\n",
      "Success rate:0.75%\n",
      "Correctly labeled: 69 out of 73 positive reviews\n",
      "Sensitivity:0.95%\n",
      "Correctly labeled: 118 out of 176 negative reviews\n",
      "Specificity:0.67%\n",
      "\n",
      "Mislabeled 71 points out of 250\n",
      "Success rate:0.72%\n",
      "Correctly labeled: 67 out of 71 positive reviews\n",
      "Sensitivity:0.94%\n",
      "Correctly labeled: 112 out of 179 negative reviews\n",
      "Specificity:0.63%\n",
      "\n",
      "Mislabeled 76 points out of 250\n",
      "Success rate:0.70%\n",
      "Correctly labeled: 49 out of 50 positive reviews\n",
      "Sensitivity:0.98%\n",
      "Correctly labeled: 125 out of 200 negative reviews\n",
      "Specificity:0.62%\n",
      "\n",
      "Mislabeled 73 points out of 250\n",
      "Success rate:0.71%\n",
      "Correctly labeled: 49 out of 56 positive reviews\n",
      "Sensitivity:0.88%\n",
      "Correctly labeled: 128 out of 194 negative reviews\n",
      "Specificity:0.66%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "naive_bayes_cross_validation(model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mislabeled 69 points out of 249\n",
      "Success rate:0.72%\n",
      "Correctly labeled: 122 out of 186 positive reviews\n",
      "Sensitivity:0.66%\n",
      "Correctly labeled: 58 out of 63 negative reviews\n",
      "Specificity:0.92%\n",
      "\n",
      "Mislabeled 76 points out of 250\n",
      "Success rate:0.70%\n",
      "Correctly labeled: 127 out of 196 positive reviews\n",
      "Sensitivity:0.65%\n",
      "Correctly labeled: 47 out of 54 negative reviews\n",
      "Specificity:0.87%\n",
      "\n",
      "Mislabeled 86 points out of 250\n",
      "Success rate:0.66%\n",
      "Correctly labeled: 114 out of 190 positive reviews\n",
      "Sensitivity:0.60%\n",
      "Correctly labeled: 50 out of 60 negative reviews\n",
      "Specificity:0.83%\n",
      "\n",
      "Mislabeled 90 points out of 250\n",
      "Success rate:0.64%\n",
      "Correctly labeled: 108 out of 191 positive reviews\n",
      "Sensitivity:0.57%\n",
      "Correctly labeled: 52 out of 59 negative reviews\n",
      "Specificity:0.88%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "naive_bayes_cross_validation(model1a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall it has a decrease in the model's accuracy, however it makes a huge difference in our ability to label negative reviews properly.\n",
    "\n",
    "Essentially, the model would need to be adjusted depending on what the stakeholders are more willing to live with: more false positives, or more false negatives."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
